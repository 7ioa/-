{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd0dc491",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-20T06:27:07.852700Z",
     "iopub.status.busy": "2025-11-20T06:27:07.852014Z",
     "iopub.status.idle": "2025-11-20T06:27:09.374512Z",
     "shell.execute_reply": "2025-11-20T06:27:09.373642Z"
    },
    "papermill": {
     "duration": 1.52662,
     "end_time": "2025-11-20T06:27:09.376064",
     "exception": false,
     "start_time": "2025-11-20T06:27:07.849444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/timellm-else/else/dataset/ETT-small/ETTh2.csv\n",
      "/kaggle/input/timellm-else/else/dataset/ETT-small/ETTm2.csv\n",
      "/kaggle/input/timellm-else/else/dataset/ETT-small/ETTm1.csv\n",
      "/kaggle/input/timellm-else/else/dataset/ETT-small/ETTh1.csv\n",
      "/kaggle/input/timellm-else/else/models/BERT/config.json\n",
      "/kaggle/input/timellm-else/else/models/BERT/tokenizer.json\n",
      "/kaggle/input/timellm-else/else/models/BERT/pytorch_model.bin\n",
      "/kaggle/input/timellm-else/else/models/BERT/vocab.txt\n",
      "/kaggle/input/timellm-else/else/models/gpt2/config.json\n",
      "/kaggle/input/timellm-else/else/models/gpt2/merges.txt\n",
      "/kaggle/input/timellm-else/else/models/gpt2/tokenizer.json\n",
      "/kaggle/input/timellm-else/else/models/gpt2/vocab.json\n",
      "/kaggle/input/timellm-else/else/models/gpt2/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da8b9148",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T06:27:09.380772Z",
     "iopub.status.busy": "2025-11-20T06:27:09.380137Z",
     "iopub.status.idle": "2025-11-20T06:27:10.172145Z",
     "shell.execute_reply": "2025-11-20T06:27:10.171442Z"
    },
    "papermill": {
     "duration": 0.79547,
     "end_time": "2025-11-20T06:27:10.173472",
     "exception": false,
     "start_time": "2025-11-20T06:27:09.378002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Time-LLM'...\r\n",
      "remote: Enumerating objects: 189, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\r\n",
      "remote: Total 189 (delta 0), reused 1 (delta 0), pack-reused 186 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (189/189), 1.09 MiB | 8.16 MiB/s, done.\r\n",
      "Resolving deltas: 100% (92/92), done.\r\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/KimMeen/Time-LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c88a8e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T06:27:10.178073Z",
     "iopub.status.busy": "2025-11-20T06:27:10.177844Z",
     "iopub.status.idle": "2025-11-20T06:27:16.772331Z",
     "shell.execute_reply": "2025-11-20T06:27:16.771462Z"
    },
    "papermill": {
     "duration": 6.598399,
     "end_time": "2025-11-20T06:27:16.773603",
     "exception": false,
     "start_time": "2025-11-20T06:27:10.175204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件复制成功！\n",
      "当前工作目录: /kaggle/working/Time-LLM/models/gpt2\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# 定义源路径（你上传的数据集在input中的路径）和目标路径\n",
    "source_path = '/kaggle/input/timellm-else/else/models/gpt2'\n",
    "destination_path = '/kaggle/working/Time-LLM/models/gpt2'\n",
    "\n",
    "# 使用shutil.copytree递归复制整个目录\n",
    "if not os.path.exists(destination_path):\n",
    "    shutil.copytree(source_path, destination_path)\n",
    "    print(\"文件复制成功！\")\n",
    "else:\n",
    "    print(\"目标目录已存在，为避免覆盖，跳过复制。\")\n",
    "\n",
    "# 更改当前工作目录到你的项目文件夹\n",
    "os.chdir(destination_path)\n",
    "print(\"当前工作目录:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56cfcdf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T06:27:16.778077Z",
     "iopub.status.busy": "2025-11-20T06:27:16.777853Z",
     "iopub.status.idle": "2025-11-20T06:27:56.775405Z",
     "shell.execute_reply": "2025-11-20T06:27:56.774609Z"
    },
    "papermill": {
     "duration": 40.001397,
     "end_time": "2025-11-20T06:27:56.776892",
     "exception": false,
     "start_time": "2025-11-20T06:27:16.775495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.\r\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\r\n",
      "\t`--num_machines` was set to a value of `1`\r\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\r\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\r\n",
      "/usr/bin/python3: can't open file '/kaggle/working/Time-LLM/models/gpt2/run_main.py': [Errno 2] No such file or directory\r\n",
      "/usr/bin/python3: can't open file '/kaggle/working/Time-LLM/models/gpt2/run_main.py': [Errno 2] No such file or directory\r\n",
      "W1120 06:27:34.738000 55 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 64 closing signal SIGTERM\r\n",
      "W1120 06:27:34.739000 55 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 66 closing signal SIGTERM\r\n",
      "W1120 06:27:34.739000 55 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 67 closing signal SIGTERM\r\n",
      "W1120 06:27:34.740000 55 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 68 closing signal SIGTERM\r\n",
      "W1120 06:27:34.740000 55 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 69 closing signal SIGTERM\r\n",
      "W1120 06:27:34.741000 55 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 70 closing signal SIGTERM\r\n",
      "E1120 06:27:34.743000 55 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 2) local_rank: 0 (pid: 63) of binary: /usr/bin/python3\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/local/bin/accelerate\", line 10, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "             ^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1190, in launch_command\r\n",
      "    multi_gpu_launcher(args)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 815, in multi_gpu_launcher\r\n",
      "    distrib_run.run(args)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 909, in run\r\n",
      "    elastic_launch(\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 138, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\r\n",
      "    raise ChildFailedError(\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "run_main.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "[1]:\r\n",
      "  time      : 2025-11-20_06:27:34\r\n",
      "  host      : 5ed372799a8e\r\n",
      "  rank      : 2 (local_rank: 2)\r\n",
      "  exitcode  : 2 (pid: 65)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2025-11-20_06:27:34\r\n",
      "  host      : 5ed372799a8e\r\n",
      "  rank      : 0 (local_rank: 0)\r\n",
      "  exitcode  : 2 (pid: 63)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.\r\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\r\n",
      "\t`--num_machines` was set to a value of `1`\r\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\r\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\r\n",
      "/usr/bin/python3: can't open file '/kaggle/working/Time-LLM/models/gpt2/run_main.py': [Errno 2] No such file or directory\r\n",
      "/usr/bin/python3: can't open file '/kaggle/working/Time-LLM/models/gpt2/run_main.py': [Errno 2] No such file or directory\r\n",
      "/usr/bin/python3: can't open file '/kaggle/working/Time-LLM/models/gpt2/run_main.py': [Errno 2] No such file or directory\r\n",
      "/usr/bin/python3: can't open file '/kaggle/working/Time-LLM/models/gpt2/run_main.py': [Errno 2] No such file or directory\r\n",
      "/usr/bin/python3: can't open file '/kaggle/working/Time-LLM/models/gpt2/run_main.py': [Errno 2] No such file or directory\r\n",
      "/usr/bin/python3: can't open file '/kaggle/working/Time-LLM/models/gpt2/run_main.py': [Errno 2] No such file or directory\r\n",
      "/usr/bin/python3: can't open file '/kaggle/working/Time-LLM/models/gpt2/run_main.py': [Errno 2] No such file or directory\r\n",
      "/usr/bin/python3: can't open file '/kaggle/working/Time-LLM/models/gpt2/run_main.py': [Errno 2] No such file or directory\r\n",
      "E1120 06:27:42.142000 71 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 2) local_rank: 0 (pid: 79) of binary: /usr/bin/python3\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/local/bin/accelerate\", line 10, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "             ^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1190, in launch_command\r\n",
      "    multi_gpu_launcher(args)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 815, in multi_gpu_launcher\r\n",
      "    distrib_run.run(args)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 909, in run\r\n",
      "    elastic_launch(\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 138, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\r\n",
      "    raise ChildFailedError(\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "run_main.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "[1]:\r\n",
      "  time      : 2025-11-20_06:27:42\r\n",
      "  host      : 5ed372799a8e\r\n",
      "  rank      : 1 (local_rank: 1)\r\n",
      "  exitcode  : 2 (pid: 80)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "[2]:\r\n",
      "  time      : 2025-11-20_06:27:42\r\n",
      "  host      : 5ed372799a8e\r\n",
      "  rank      : 2 (local_rank: 2)\r\n",
      "  exitcode  : 2 (pid: 81)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "[3]:\r\n",
      "  time      : 2025-11-20_06:27:42\r\n",
      "  host      : 5ed372799a8e\r\n",
      "  rank      : 3 (local_rank: 3)\r\n",
      "  exitcode  : 2 (pid: 82)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "[4]:\r\n",
      "  time      : 2025-11-20_06:27:42\r\n",
      "  host      : 5ed372799a8e\r\n",
      "  rank      : 4 (local_rank: 4)\r\n",
      "  exitcode  : 2 (pid: 83)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "[5]:\r\n",
      "  time      : 2025-11-20_06:27:42\r\n",
      "  host      : 5ed372799a8e\r\n",
      "  rank      : 5 (local_rank: 5)\r\n",
      "  exitcode  : 2 (pid: 84)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "[6]:\r\n",
      "  time      : 2025-11-20_06:27:42\r\n",
      "  host      : 5ed372799a8e\r\n",
      "  rank      : 6 (local_rank: 6)\r\n",
      "  exitcode  : 2 (pid: 85)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "[7]:\r\n",
      "  time      : 2025-11-20_06:27:42\r\n",
      "  host      : 5ed372799a8e\r\n",
      "  rank      : 7 (local_rank: 7)\r\n",
      "  exitcode  : 2 (pid: 86)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2025-11-20_06:27:42\r\n",
      "  host      : 5ed372799a8e\r\n",
      "  rank      : 0 (local_rank: 0)\r\n",
      "  exitcode  : 2 (pid: 79)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.\r\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\r\n",
      "\t`--num_machines` was set to a value of `1`\r\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\r\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\r\n",
      "/usr/bin/python3: can't open file '/kaggle/working/Time-LLM/models/gpt2/run_main.py': [Errno 2] No such file or directory\r\n",
      "W1120 06:27:48.980000 87 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 95 closing signal SIGTERM\r\n",
      "W1120 06:27:48.981000 87 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 96 closing signal SIGTERM\r\n",
      "W1120 06:27:48.981000 87 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 98 closing signal SIGTERM\r\n",
      "W1120 06:27:48.982000 87 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 99 closing signal SIGTERM\r\n",
      "W1120 06:27:48.982000 87 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 100 closing signal SIGTERM\r\n",
      "W1120 06:27:48.982000 87 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 101 closing signal SIGTERM\r\n",
      "W1120 06:27:48.983000 87 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 102 closing signal SIGTERM\r\n",
      "E1120 06:27:48.986000 87 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 2) local_rank: 2 (pid: 97) of binary: /usr/bin/python3\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/local/bin/accelerate\", line 10, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "             ^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1190, in launch_command\r\n",
      "    multi_gpu_launcher(args)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 815, in multi_gpu_launcher\r\n",
      "    distrib_run.run(args)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 909, in run\r\n",
      "    elastic_launch(\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 138, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\r\n",
      "    raise ChildFailedError(\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "run_main.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "  <NO_OTHER_FAILURES>\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2025-11-20_06:27:48\r\n",
      "  host      : 5ed372799a8e\r\n",
      "  rank      : 2 (local_rank: 2)\r\n",
      "  exitcode  : 2 (pid: 97)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.\r\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\r\n",
      "\t`--num_machines` was set to a value of `1`\r\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\r\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\r\n",
      "/usr/bin/python3: can't open file '/kaggle/working/Time-LLM/models/gpt2/run_main.py': [Errno 2] No such file or directory\r\n",
      "W1120 06:27:55.786000 103 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 111 closing signal SIGTERM\r\n",
      "W1120 06:27:55.787000 103 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 112 closing signal SIGTERM\r\n",
      "W1120 06:27:55.787000 103 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 114 closing signal SIGTERM\r\n",
      "W1120 06:27:55.787000 103 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 115 closing signal SIGTERM\r\n",
      "W1120 06:27:55.788000 103 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 116 closing signal SIGTERM\r\n",
      "W1120 06:27:55.788000 103 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 117 closing signal SIGTERM\r\n",
      "W1120 06:27:55.789000 103 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 118 closing signal SIGTERM\r\n",
      "E1120 06:27:55.791000 103 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 2) local_rank: 2 (pid: 113) of binary: /usr/bin/python3\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/local/bin/accelerate\", line 10, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "             ^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1190, in launch_command\r\n",
      "    multi_gpu_launcher(args)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 815, in multi_gpu_launcher\r\n",
      "    distrib_run.run(args)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 909, in run\r\n",
      "    elastic_launch(\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 138, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\r\n",
      "    raise ChildFailedError(\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "run_main.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "  <NO_OTHER_FAILURES>\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2025-11-20_06:27:55\r\n",
      "  host      : 5ed372799a8e\r\n",
      "  rank      : 2 (local_rank: 2)\r\n",
      "  exitcode  : 2 (pid: 113)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n"
     ]
    }
   ],
   "source": [
    "!bash /kaggle/working/Time-LLM/scripts/TimeLLM_ETTh1.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2a5fc7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T06:27:56.783449Z",
     "iopub.status.busy": "2025-11-20T06:27:56.783187Z",
     "iopub.status.idle": "2025-11-20T06:27:56.913240Z",
     "shell.execute_reply": "2025-11-20T06:27:56.912357Z"
    },
    "papermill": {
     "duration": 0.134841,
     "end_time": "2025-11-20T06:27:56.914556",
     "exception": false,
     "start_time": "2025-11-20T06:27:56.779715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface  input  lib  nbdev\tsrc  working\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8786123,
     "sourceId": 13799798,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 53.231003,
   "end_time": "2025-11-20T06:27:57.234373",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-20T06:27:04.003370",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
